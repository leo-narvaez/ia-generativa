{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        azure_endpoint = endpoint, \n",
    "        api_key=api_key,\n",
    "        api_version=\"2024-02-01\"\n",
    "    )\n",
    "\n",
    "CHAT_COMPLETIONS_MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Few Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòç,üëè,‚ú®,üéâ,üíñ\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot classification\n",
    "system_prompt =\"\"\"Predict up to 5 emojis as a response to a text chat message. The output\n",
    "should only include emojis.\n",
    "\n",
    "input: The new visual design is blowing my mind ü§Ø\n",
    "output: ‚ûï,üíò, ‚ù§‚Äçüî•\n",
    "\n",
    "input: Well that looks great regardless\n",
    "output: ‚ù§Ô∏è,ü™Ñ\n",
    "\n",
    "input: Unfortunately this won't work\n",
    "output: üíî,üòî\n",
    "\n",
    "input: sounds good, I'll look into that\n",
    "output: üôè,üëç\n",
    "\n",
    "input: 10hr cut of jeff goldblum laughing URL\n",
    "output: üòÇ,üíÄ,‚ö∞Ô∏è\n",
    "\"\"\"\n",
    "user_prompt = \"The new user interface is amazing!\"\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages = [{\"role\":\"system\", \"content\":system_prompt},\n",
    "                {\"role\":\"user\",\"content\": user_prompt,}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering Best Practices\n",
    "\n",
    "## Write clear instructions\n",
    "\n",
    "Examples:\n",
    "\n",
    "-----------------------\n",
    "Prompt:\n",
    "\n",
    "Write code to calculate the Fibonacci sequence.\n",
    "\n",
    "Better:\n",
    "\n",
    "Write a TypeScript function to efficiently calculate the Fibonacci sequence. Comment the code liberally to explain what each piece does and why it's written that way.\n",
    "\n",
    "----------------------\n",
    "\n",
    "Prompt:\n",
    "\n",
    "Summarize the meeting notes.\n",
    "\n",
    "Better:\n",
    "\n",
    "Summarize the meeting notes in a single paragraph. Then write a markdown list of the speakers and each of their key points. Finally, list the next steps or action items suggested by the speakers, if any.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role Playing\n",
    "\n",
    "Examples:\n",
    "\n",
    "-----------------------\n",
    "\n",
    "System Message: When I ask for help to write something, you will reply with a document that contains at least one joke or playful comment in every paragraph.\n",
    "\n",
    "----------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment input text\n",
    "\n",
    "Examples:\n",
    "\n",
    "------------------------\n",
    "\n",
    "user message: Summarize the text delimited by triple quotes with a haiku.\n",
    "\n",
    "\"\"\"insert text here\"\"\"\n",
    "\n",
    "------------------------\n",
    "\n",
    "system message: You will be provided with a pair of articles (delimited with XML tags) about the same topic. First summarize the arguments of each article. Then indicate which of them makes a better argument and explain why.\n",
    "\n",
    "user message: \n",
    "\n",
    "\\<article> insert first article here \\</article>\n",
    "\n",
    "\\<article> insert second article here \\</article>\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain steps and processes to complete a task\n",
    "\n",
    "Examples:\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "System Message:\n",
    "Use the following step-by-step instructions to respond to user inputs.\n",
    "\n",
    "Step 1 - The user will provide you with text in triple quotes. Summarize this text in one sentence with a prefix that says \"Summary: \".\n",
    "\n",
    "Step 2 - Translate the summary from Step 1 into Spanish, with a prefix that says \"Translation: \".\n",
    "\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Clasificaci√≥n de Emojis con Zero-shot\n",
    "Enunciado:\n",
    "Dado el siguiente texto, predice hasta 5 emojis que mejor representen la emoci√≥n o el tema del mensaje. Usa el modelo de Zero-shot para hacer la clasificaci√≥n.\n",
    "\n",
    "Texto: \"Estoy tan feliz que no puedo dejar de sonre√≠r.\"\n",
    "\n",
    "Resultado esperado: üòÑ,üòä,‚ú®,üåû,‚ù§Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòÑüòäüòÄüòÅü•≥\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Estoy tan feliz que no puedo dejar de sonre√≠r.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an emoji classification assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Texto: {user_prompt}. ¬øCu√°les son los 5 emojis que mejor representan la emoci√≥n o el tema del mensaje?, muestra solo los emojis\"},\n",
    "    ],\n",
    "    max_tokens=70,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Traducci√≥n de Resumen\n",
    "Enunciado:\n",
    "El siguiente texto es una transcripci√≥n de una reuni√≥n. Res√∫melo en una sola oraci√≥n, luego traduce ese resumen al ingl√©s.\n",
    "\n",
    "Texto:\n",
    "\"\"\"Hoy discutimos sobre la necesidad de mejorar la interfaz de usuario en el sitio web. Los participantes estuvieron de acuerdo en que se debe hacer m√°s intuitiva y accesible, especialmente para usuarios mayores. Tambi√©n se mencion√≥ la importancia de agregar soporte multiling√ºe.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Hoy se convers√≥ sobre la importancia de mejorar la interfaz de usuario del sitio web para hacerla m√°s intuitiva y accesible, especialmente para usuarios mayores, y se destac√≥ la necesidad de incorporar soporte multiling√ºe.\n",
      "Translation: Today, the discussion focused on the importance of enhancing the website's user interface to make it more intuitive and accessible, especially for older users, and the need to incorporate multilingual support was emphasized.\n"
     ]
    }
   ],
   "source": [
    "# Texto a resumir\n",
    "user_prompt = \"\"\"Hoy discutimos sobre la necesidad de mejorar la interfaz de usuario en el sitio web. Los participantes estuvieron de acuerdo en que se debe hacer m√°s intuitiva y accesible, especialmente para usuarios mayores. Tambi√©n se mencion√≥ la importancia de agregar soporte multiling√ºe.\"\"\"\n",
    "\n",
    "# Paso 1: Resumir el texto\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a summarization assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Resume el siguiente texto en una sola oraci√≥n: {user_prompt}\"}\n",
    "    ],\n",
    "    max_tokens=100,\n",
    ")\n",
    "summary = response.choices[0].message.content\n",
    "print(f\"Summary: {summary}\")\n",
    "\n",
    "# Paso 2: Traducir el resumen al ingl√©s\n",
    "translation_prompt = f\"Traduce el siguiente resumen al ingl√©s: {summary}\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a translation assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": translation_prompt}\n",
    "    ],\n",
    "    max_tokens=100,\n",
    ")\n",
    "print(f\"Translation: {response.choices[0].message.content}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Respuesta Autom√°tica con Role-playing\n",
    "Enunciado:\n",
    "Configura un modelo para responder a una solicitud de escritura, haciendo que la respuesta contenga un toque de humor. Usa la siguiente solicitud como ejemplo.\n",
    "\n",
    "Solicitud:\n",
    "\"Escribe una carta formal solicitando d√≠as de vacaciones.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tu Nombre]  \n",
      "[Tu Direcci√≥n]  \n",
      "[Ciudad, Estado, C√≥digo Postal]  \n",
      "[Tu Correo Electr√≥nico]  \n",
      "[Tu N√∫mero de Tel√©fono]  \n",
      "[Fecha]  \n",
      "\n",
      "[Nombre del Jefe o Superior]  \n",
      "[Nombre de la Empresa]  \n",
      "[Direcci√≥n de la Empresa]  \n",
      "[Ciudad, Estado, C√≥digo Postal]  \n",
      "\n",
      "Estimado/a [Nombre del Jefe o Superior]:\n",
      "\n",
      "Espero que este mensaje le encuentre disfrutando de un caf√© bien cargado y en plena forma para enfrentar el d√≠a. \n",
      "\n",
      "Me dirijo a usted para solicitar formalmente algunos d√≠as de vacaciones, ya que creo que mi cerebro y mi cuerpo han llegado a un acuerdo mutuo: es necesario tomar un descanso antes de que comiencen a planear su jubilaci√≥n. Mis d√≠as de vacaciones solicitados son del [fecha de inicio] al [fecha de finalizaci√≥n], y me asegurar√© de que todas mis responsabilidades est√©n al d√≠a antes de mi partida. Esto incluye dejar todo en perfecto orden, como un maestro de ceremonias que se asegura de que todo est√© preparado para el gran evento.\n",
      "\n",
      "Estoy seguro/a de que el equipo podr√° manejar el flujo de trabajo durante mi ausencia sin problemas, y me comprometo a dejar instrucciones claras y a estar disponible para cualquier consulta que pueda surgir, aunque con un ligero desfase horario mientras est√© recargando energ√≠as.\n",
      "\n",
      "Agradezco de antemano su comprensi√≥n y apoyo en esta solicitud. Espero su respuesta con la misma expectativa con la que un ni√±o espera abrir sus regalos de cumplea√±os.\n",
      "\n",
      "Sin m√°s, quedo a la espera de su aprobaci√≥n y, por supuesto, de mis d√≠as de descanso.\n",
      "\n",
      "Atentamente,  \n",
      "[Firma (si es en papel)]  \n",
      "[Tu Nombre]  \n",
      "[Tu Puesto]  \n"
     ]
    }
   ],
   "source": [
    "# Instrucciones para el modelo (system_prompt) para darle el toque de humor a la carta\n",
    "system_prompt = \"\"\"\n",
    "Eres un asistente de escritura profesional. Ayuda al usuario a escribir una carta formal solicitando d√≠as de vacaciones. La carta debe ser respetuosa y clara, pero tambi√©n debe incluir un toque de humor sutil para hacerla m√°s ligera y agradable. \n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"Escribe una carta formal solicitando d√≠as de vacaciones.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": user_prompt}]\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta generada\n",
    "print(response.choices[0].message.content)  # Ejemplo de salida: carta con broma\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Segmentaci√≥n de Texto\n",
    "Enunciado:\n",
    "Segmenta un texto delimitado por comillas triples y luego trad√∫celo a otro idioma (por ejemplo, ingl√©s). Aplica el siguiente formato de entrada de texto y muestra c√≥mo lo har√≠as.\n",
    "\n",
    "Texto de Entrada:\n",
    "\"\"\"Hoy es un buen d√≠a para aprender nuevas cosas y mejorar nuestras habilidades. ¬°El futuro est√° lleno de oportunidades!\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentaci√≥n:\n",
      "\n",
      "1. Hoy es un buen d√≠a para aprender nuevas cosas \n",
      "2. y mejorar nuestras habilidades.\n",
      "3. ¬°El futuro est√° lleno de oportunidades!\n",
      "\n",
      "Traducci√≥n al ingl√©s:\n",
      "\n",
      "1. Today is a good day to learn new things \n",
      "2. and improve our skills.\n",
      "3. The future is full of opportunities!\n"
     ]
    }
   ],
   "source": [
    "# Instrucciones para segmentar el texto y luego traducirlo\n",
    "system_prompt = \"\"\"\n",
    "Eres un asistente de traducci√≥n. Tu tarea es dividir un texto largo en segmentos m√°s peque√±os y luego traducir cada segmento al ingl√©s. Aseg√∫rate de que cada fragmento mantenga el contexto y el significado original. Despu√©s de segmentar, traduce al ingl√©s el texto segmentado.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"Hoy es un buen d√≠a para aprender nuevas cosas y mejorar nuestras habilidades. ¬°El futuro est√° lleno de oportunidades!\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": user_prompt}]\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta generada\n",
    "print(response.choices[0].message.content)  # Salida esperada: segmentaci√≥n en espa√±ol e ingl√©s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6: Predicci√≥n de Emojis con Zero-shot\n",
    "Enunciado:\n",
    "Realiza una clasificaci√≥n Zero-shot utilizando el modelo y predice hasta 5 emojis para el siguiente mensaje:\n",
    "\n",
    "Texto de entrada:\n",
    "\"Estoy muy cansado, pero contento con el trabajo que he hecho.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòåüí™üåüüò¥üòä\n"
     ]
    }
   ],
   "source": [
    "# Instrucciones para predecir emojis basados en el texto\n",
    "system_prompt = \"\"\"Predice hasta 5 emojis como respuesta a un mensaje de chat. La salida debe solo incluir emojis.\"\"\"\n",
    "user_prompt = \"Estoy muy cansado, pero contento con el trabajo que he hecho.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": user_prompt}]\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta generada\n",
    "print(response.choices[0].message.content)  # Ejemplo de salida: \"üòÖ,üí™,üëå\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7: Predicci√≥n de Emojis con Few-shot Learning\n",
    "\n",
    "Enunciado:\n",
    "\n",
    "En este ejercicio utilizar√°s Few-shot learning con roles (system, user, assistant) para predecir emojis. En Few-shot learning, proporcionamos ejemplos espec√≠ficos de interacciones para que el modelo aprenda a generalizar la tarea con pocos ejemplos.\n",
    "\n",
    "Dado un conjunto de ejemplos de interacciones entre un usuario y un asistente, utiliza el modelo para predecir hasta 5 emojis para el siguiente mensaje:\n",
    "\n",
    "Mensaje: \"Estoy muy cansado, pero contento con el trabajo que he hecho.\"\n",
    "\n",
    "Devuelve solo los emojis, separados por comas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòå,üí™,üòä,üíº\n"
     ]
    }
   ],
   "source": [
    "# Definir el prompt con Few-shot utilizando m√∫ltiples roles\n",
    "few_shot_prompt = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant that predicts emojis based on user text.\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Estoy muy feliz con mi nuevo trabajo.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üòä,üéâ,üíº,üí™\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"No me siento bien, tengo dolor de cabeza.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üòû,ü§ï,üíî\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Hoy es un d√≠a incre√≠ble para correr al aire libre.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üèÉ‚Äç‚ôÇÔ∏è,üå≥,üåû,üí®\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Acabo de terminar de ver una pel√≠cula emocionante.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üé¨,üëè,üò±,‚ù§Ô∏è\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Voy a dormir temprano, me siento agotado.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üò¥,üõèÔ∏è,üò¥\"},\n",
    "    \n",
    "    # Ahora pedimos la predicci√≥n para el nuevo mensaje\n",
    "    {\"role\": \"user\", \"content\": \"Estoy muy cansado, pero contento con el trabajo que he hecho.\"},\n",
    "]\n",
    "\n",
    "# Llamada a la API para obtener la predicci√≥n de emojis\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages=few_shot_prompt\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta generada\n",
    "print(response.choices[0].message.content)  # Ejemplo de salida: \"üòÖ,üí™,üëå\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
